{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAZONtewwssT",
        "outputId": "4061711d-334c-41e9-8c8d-e9b799340dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents  \"openai-agents[litellm]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "d5YeMtkD42b7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str)->str:\n",
        "    print(f\"[debug] getting weather for {city}\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "Wheather_Agent = Agent(\n",
        "    name=\"WeatherAssistant\",\n",
        "    instructions=\"You will answer weather relevant question\",\n",
        "    model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    tools=[get_weather],\n",
        "    handoff_description=\"Weather asistance is specialized for all weather queries \",\n",
        ")\n",
        "\n",
        "Panaversity_Agent = Agent(\n",
        "    name=\"anaversityAssistant\",\n",
        "    instructions=\"You will answer weather relevant question\",\n",
        "    model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    handoff_description=\"Panaversity asistance is specialized for all Panaversity queries,panaversity is global learner AI Agent education and pioneered daca arch.\",\n",
        ")\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name=\"GeneralAssistant\",\n",
        "    instructions=\"You will chat with user for general question and hand  offs specialized Asistants when needed i.e WheatherAsistant for wheather queries and Panaversity Asistant for all AI education and Panaversity related question \",\n",
        "    model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    handoffs=[Wheather_Agent,Panaversity_Agent]\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(triage_agent, \"Hi\")\n",
        "print(result.final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI8x-evR5cqa",
        "outputId": "2c0f52b3-d32b-4796-e75c-37e2b30fc406"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there! How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = Runner.run_sync(triage_agent, \"what is the weather of islamabad\")\n",
        "print(result.final_output)\n",
        "result.last_agent.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "7kcdhSCzBWLb",
        "outputId": "1931d48b-93f3-4948-ba5e-2b82b4ce1c20"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] getting weather for islamabad\n",
            "The weather in islamabad is sunny.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WeatherAssistant'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = Runner.run_sync(triage_agent, \"what is Panaversity\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "id": "eaVeZ9hBCAwb",
        "outputId": "272ee2a4-6d37-438e-b218-beafd6913a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am now talking to the weather assistant. How can I help you with weather-related questions?\n",
            "\n"
          ]
        }
      ]
    }
  ]
}